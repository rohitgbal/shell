<?xml version="1.0" encoding="UTF-8"?>
<workflow-app xmlns="uri:oozie:workflow:0.5" name="prg1${project}_${workflow}_WF">
    <global>
        <job-tracker>${job_tracker}</job-tracker>
        <name-node>${name_node}</name-node>

        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${oozie_queue_name}</value>
            </property>
            <property>
                <name>oozie.launcher.mapreduce.job.user.classpath.first</name>
                <value>true</value>
            </property>
            <property>
                <name>oozie.launcher.mapreduce.task.classpath.user.precedence</name>
                <value>true</value>
            </property>
            <property>
                <name>oozie.launcher.mapreduce.map.memory.mb</name>
                <value>32768</value>
            </property>
            <property>
                <name>oozie.launcher.mapreduce.map.java.opts</name>
                <value>-Xmx24576m</value>
            </property>

            <property>
                <name>oozie.launcher.yarn.app.mapreduce.am.resource.mb</name>
                <value>32768</value>
            </property>
            <property>
                <name>oozie.launcher.yarn.app.mapreduce.am.command-opts</name>
                <value>-Xmx24576m</value>
            </property>
        </configuration>
    </global>
    <credentials>
        <credential name="hiveCredentials" type="hive2">
            <property>
                <name>hive2.jdbc.url</name>
                <value>${hive_beeline_server}</value>
            </property>
            <property>
                <name>hive2.server.principal</name>
                <value>${hive_kerberos_principal}</value>
            </property>
        </credential>
    </credentials>
    <start to="HistoryLoad_Check" />

    <!-- To check the Historical Load -->
    <decision name="HistoryLoad_Check">
        <switch>
            <case to="LoaddevpactHistory_Stage"> ${Incremental eq "false"} </case>
            <default to="LoaddevpactDaily_Input_Check" />
        </switch>
    </decision>

    <!-- I/P File Check -->
    <decision name="LoaddevpactDaily_Input_Check">
        <switch>
            <case to="LoaddevpactHistory_Move_to_Inprocess"> ${fs:dirSize(raw_input_location) gt 0} </case>
            <default to="end" />
        </switch>
    </decision>

    <!-- Move files from Input MKD folder to Inprocess Folder -->
    <action name="LoaddevpactHistory_Move_to_Inprocess">
        <java>
            <prepare>
                <delete path="${name_node}${raw_inprocess_location}"/>
                <mkdir path="${name_node}${raw_inprocess_location}"/>
            </prepare>
            <main-class>${hdfs_mass_move_class}</main-class>
            <java-opts>-Dsun.security.krb5.debug=true</java-opts>
            <arg>${raw_input_location}/</arg>
            <arg>${raw_inprocess_location}/</arg>
            <file>${path_hdfs_prg1_lib}/prg1Common.jar#prg1Common.jar</file>
            <file>${path_hdfs_prg1_lib}/lib/itcore.jar#itcore.jar</file>
            <file>${environment_hdfs_folder}/Workflow/KEYS/prg1_jaas.conf#prg1_jaas.conf</file>
            <file>${kerberos_keytab_file}#${kerberos_keytab_filename}</file>
        </java>
        <ok to="LoaddevpactHistory_Stg_To_Archive"/>
        <error to="LoaddevpactHistory_Stg_To_Archive"/>
    </action>

	 <!-- Load devpact Archive table -->
    <action name="LoaddevpactHistory_Stg_To_Archive" cred="hiveCredentials">
        <hive2 xmlns="uri:oozie:hive2-action:0.1">
            <jdbc-url>${hive_beeline_server}</jdbc-url>
            <script>${path_hdfs_workflow_root}/LoadArchivedevpact.ql</script>
            <param>db_name=${hive_database_name}</param>
            <param>current_date=${current_date}</param>
            <param>arcv_days=${arcv_days}</param>
            <param>current_user=${kerberos_user_name}</param>
            <file>${path_hdfs_workflow_root}/LoadArchivedevpact.ql#LoadArchivedevpact.ql</file>
        </hive2>
        <ok to="LoaddevpactHistory_Stage" />
        <error to="LoaddevpactHistory_Stage" />
    </action>


    <!-- Move files from Inprocess Folder to staging table -->
    <action name="LoaddevpactHistory_Stage">
        <shell xmlns="uri:oozie:shell-action:0.3">
            <prepare>
                <delete path="${name_node}${path_hdfs_staging}/nscvsfy_tcx_hist_st_hte"/>
                <mkdir path="${name_node}${path_hdfs_staging}/nscvsfy_tcx_hist_st_hte"/>
            </prepare>
            <exec>devpact.sh</exec>
            <argument>${hive_database_name}</argument>
            <argument>${raw_input_location}/</argument>
            <argument>${raw_inprocess_location}/</argument>
            <argument>${source_history_table}</argument>
            <argument>${output_staging_hdfs_path}/</argument>
            <argument>${spark_master}</argument>
            <argument>${spark_deploy_mode}</argument>
            <argument>${spark_jars}</argument>
            <argument>${spark_network_timeout}</argument>
            <argument>${spark_ui_port}</argument>
            <argument>${spark_driver_memory}</argument>
            <argument>${spark_num_executors}</argument>
            <argument>${spark_executor_memory}</argument>
            <argument>${oozie_queue_name}</argument>
            <argument>${spark_sql_shuffle_partitions}</argument>
            <argument>${spark_sql_orc_filterPushdown}</argument>
            <argument>${spark_yarn_executor_memoryOverhead}</argument>
            <argument>${spark_core_connection_ack_wait_timeout}</argument>
            <argument>${spark_task_maxfailures}</argument>
            <argument>${spark_shuffle_io_maxRetries}</argument>
            <argument>${spark_dynamicalLocation_enabled}</argument>
            <argument>${spark_sql_orc_enabled}</argument>
            <argument>${spark_sql_hive_convertMetaStoreOrc}</argument>
            <argument>${spark_sql_orc_char_enabled}</argument>
            <argument>${spark_files}</argument>
            <argument>${kerberos_principal}</argument>
            <argument>${kerberos_keytab_filename}</argument>
            <argument>${Incremental}</argument>
            <argument>${current_user}</argument>
            <argument>${json_jar1}</argument>
            <argument>${json_jar2}</argument>
            <argument>${MKD_schedule_query_days}</argument>
            <argument>${current_date}</argument>
            <file>${path_hdfs_workflow_root}/devpact.sh#devpact.sh</file>
            <file>${path_hdfs_workflow_root}/devpact.py#devpact.py</file>
            <file>${kerberos_keytab_file}#${kerberos_keytab_filename}</file>
        </shell>

        <ok to="LoaddevpactHistory_Stg_To_Master" />
        <error to="On_Failure" />
    </action>

    <!-- Load devpact Master table -->
    <action name="LoaddevpactHistory_Stg_To_Master" cred="hiveCredentials">
        <hive2 xmlns="uri:oozie:hive2-action:0.1">
            <jdbc-url>${hive_beeline_server}</jdbc-url>
            <script>${path_hdfs_workflow_root}/LoadMasterdevpact.ql</script>
            <param>db_name=${hive_database_name}</param>
            <param>current_user=${kerberos_user_name}</param>
            <file>${path_hdfs_workflow_root}/LoadMasterdevpact.ql#LoadMasterdevpact.ql</file>
        </hive2>
        <ok to="Drop_Partition_tcx_ArchiveTable_Partitions" />
        <error to="Drop_Partition_tcx_ArchiveTable_Partitions" />
    </action>

		<action name="Drop_Partition_tcx_ArchiveTable_Partitions" cred="hiveCredentials">
		<java>
			<main-class>${delete_class}</main-class>
			<java-opt>-Dsun.security.krb5.debug=true</java-opt>
			<java-opt>-Djavax.security.auth.useSubjectCredsOnly=true</java-opt>
			<java-opt>-Djava.security.auth.login.config=${environment_hdfs_folder}/Workflow/KEYS/prg1_jaas.conf</java-opt>
			<arg>minHour=${delete_minHour}</arg>
			<arg>maxHour=${delete_maxHour}</arg>
			<arg>database=${hive_database_name}</arg>
			<arg>tableName=${archive_table}</arg>
			<arg>tableLocation=${archive_table_path}</arg>
			<arg>partitionColumn=${MKD_messages_partition}</arg>
			<arg>retention=${MKD_messages_retention}</arg>
			<file>${prg1_common_jar}</file>
			<file>${jar_itcore}</file>
			<file>${jar_hdfs_jdbc}</file>
			<file>${environment_hdfs_folder}/Workflow/KEYS/prg1_jaas.conf#prg1_jaas.conf</file>
			<file>${kerberos_keytab_file}</file>
		</java>
		<ok to="Capture_Success_reccalc_Schedule" />
		<error to="On_Failure" />
	</action>

    <!-- Success reccalc for devpact -->
    <action name="Capture_Success_reccalc_Schedule" cred="hiveCredentials">
        <hive2 xmlns="uri:oozie:hive2-action:0.1">
            <jdbc-url>${hive_beeline_server}</jdbc-url>
            <script>${path_hdfs_workflow_root}/success_reccalc.ql</script>
            <param>db_name=${hive_database_name}</param>
            <param>masterTableNm=${master_table_devpact}</param>
            <param>TableNm=${staging_table}</param>
            <param>sourceTableNm=${raw_input_location}</param>
            <param>currentUser=${kerberos_user_name}</param>
            <param>fileType=${reccalcFileTypeschedule}</param>
            <param>workflowId=${wf:id()}</param>
            <param>workflowName=${workflow}</param>
            <param>step_job_name=${wf:id()}_Capture_Success_reccalc</param>
        </hive2>
        <ok to="end" />
        <error to="On_Failure" />
    </action>

    <!-- Failure Files Handling in devpact -->
    <action name="On_Failure">

        <java>
            <prepare>
                <mkdir path='${name_node}${raw_failure_location}/${wf:id()}'/>
            </prepare>
            <main-class>${hdfs_mass_move_class}</main-class>
            <java-opts>-Dsun.security.krb5.debug=true</java-opts>
            <arg>${raw_inprocess_location}/</arg>
            <arg>${raw_failure_location}/${wf:id()}</arg>
            <file>${path_hdfs_prg1_lib}/prg1Common.jar#prg1Common.jar</file>
            <file>${path_hdfs_prg1_lib}/lib/itcore.jar#itcore.jar</file>
            <file>${environment_hdfs_folder}/Workflow/KEYS/prg1_jaas.conf#prg1_jaas.conf</file>
            <file>${kerberos_keytab_file}#${kerberos_keytab_filename}</file>
        </java>
        <ok to="fail" />
        <error to="fail" />
    </action>

    <kill name="fail">
        <message>Workflow failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>

    <end name="end" />
</workflow-app>
