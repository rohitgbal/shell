###########################################################################
###########################################################################
## Project      :Pace Transformation
## Work file    :prg1dataprogRepository_LoadJ9DPreJob1_WF.properties
## $Revision    :1.0  $
## $Date        :Jul 08 2020 $  
## $Author      :
## $UpDatedBy   :$
## $UpDated     :$
## Description  :This Workflow gets data from CRC4T for past 30 days and
##               staging and extracts last 15 days from transformed stg dataset  
#########################################################################

###########################################################################
#Application Configuration (prg1)
###########################################################################
application=prg1
project=dataprogRepository
workflow=LoadJ9DPreJob1
source=dataprogRepository-J9D-PJ1

###########################################################################
# Environment Based Configuration (Dev/QA/Prod)
###########################################################################
environment_hdfs_folder=/project/prg1/prg1DEV
current_user=prg1devp

###########################################################################
# Path Configuration - NAS
###########################################################################
path_edge_node_root=/e/prg1_dev

###########################################################################
# Path Configuration - HDFS
###########################################################################
path_hdfs_prg1_lib=${environment_hdfs_folder}/Workflow/lib
path_hdfs_workflow_root=${environment_hdfs_folder}/Workflow/${project}/Workflows/${workflow}
path_hdfs_common_root=${environment_hdfs_folder}/Workflow/Common/Workflows/Common
output=${environment_hdfs_folder}/project/prg1/prg1QA/Warehouse/Staging/dataprogRepository/nscvs92_J9D_pj1_st_hte

# --------------Path Locations-----
path_hdfs_staging=${environment_hdfs_folder}/Warehouse/Staging/${project}
path_hdfs_secure=${environment_hdfs_folder}/Warehouse/Secure/PaceTransformation

path_hdfs_J9D_pj1_staging_table=${path_hdfs_staging}/nscvs92_J9D_pj1_st_hte

#--------------reccalc Configuration--------------
path_hdfs_reccalc=${environment_hdfs_folder}/Warehouse/Public/reccalc
reccalc_driver_class=com.prdx.it.prg1.driver.reccalcDriver
reccalc_calculator_class=com.prdx.it.prg1.process.reccalc.ReceiveOnlyNoCountreccalcCalculator

###########################################################################
# Workflow  Configuration
###########################################################################

#------ Workflow Path --------------
workflow_path=${path_hdfs_workflow_root}/workflow.xml

#-----------Workflow Schedule Configuration--------------
frequency_interval=1440
start_date_time_in_utc=2020-07-15T00:00Z
end_date_time_in_utc=2030-12-01T00:00Z

#------ Workflow Email Configuration --------------------
email_recipient=XXXX@XXXX.COM
email_subject_failure=prg1 DEV: Workflow ${application}${project}_${workflow}_WF Failed

#------ Workflow Step Configuration ---------------------
CRC4T_J9D_pj1_query_days=30
hive_CRC4T_J9D_pj1_processdays=15


###########################################################################
# Cluster Configuration
###########################################################################
name_node=hdfs://NNDhdd2.NND.prdx.com:8020
job_tracker=NNDhdd2.NND.prdx.com:8050
log_viewer1=https://NNDhdd2e.NND.prdx.com:8000/oozie/list_oozie_workflow
log_viewer2=http://NNDhdd2.NND.prdx.com:11000/oozie/v1/job
log_viewer3=http://NNDhdd2.NND.prdx.com:11000/oozie?job=

###########################################################################
# Oozie  Configuration
###########################################################################
oozie_url=http://NNDhdd2.NND.prdx.com:11000/oozie
oozie.coord.application.path=${name_node}${path_hdfs_workflow_root}
oozie.libpath=${path_hdfs_workflow_root},${path_hdfs_prg1_lib}/lib,${path_hdfs_prg1_lib}/prg1Common.jar
oozie.use.system.libpath=true
oozie.launcher.mapreduce.task.classpath.user.precedence=true;
oozie.launcher.mapreduce.user.classpath.first=true;
oozie.launcher.mapreduce.job.user.classpath.first=true;

###########################################################################
# Database Configuration
###########################################################################

#--------------Hive Configuration----------
hive_database_name=prg1
hive_beeline_server=jdbc:hive2://NNDhdd2-zk-1.NND.prdx.com:2181,NNDhdd2-zk-2.NND.prdx.com:2181,NNDhdd2-zk-3.NND.prdx.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-apps
hive_kerberos_principal=hive/XXXX@XXXX.COM

#------------- Hbase Configuration -----------
path_hdfs_sharelib_hbase=/user/oozie/share/lib/hbase/

###########################################################################
# Kerberos Configuration
###########################################################################
kerberos_user_name=${user.name}
kerberos_principal=${user.name}@NND.prdx.COM
kerberos_keytab_filename=${user.name}.keytab
kerberos_keytab_file=${environment_hdfs_folder}/Workflow/KEYS/${kerberos_keytab_filename}

###########################################################################
#Spark Configuration
###########################################################################
spark_master=yarn
spark_network_timeout=800
spark_ui_port=5052
spark_deploy_mode=cluster
spark_jars=/usr/hdp/current/spark-client/lib/datanucleus-api-jdo-3.2.6.jar,/usr/hdp/current/spark-client/lib/datanucleus-rdbms-3.2.9.jar,/usr/hdp/current/spark-client/lib/datanucleus-core-3.2.10.jar
spark_driver_memory=16g
spark_num_executors=90
spark_executor_memory=7g
spark_executor_cores=4
spark_sql_shuffle_partitions=1000
spark_sql_orc_filterPushdown=true
spark_yarn_executor_memoryOverhead=4096k
spark_core_connection_ack_wait_timeout=600
spark_task_maxfailures=20
spark_shuffle_io_maxRetries=20
spark_dynamicalLocation_enabled=false
spark_sql_orc_enabled=true
spark_sql_hive_convertMetaStoreOrc=true
spark_sql_orc_char_enabled=true
spark_files=/usr/hdp/current/spark2-client/conf/hive-site.xml
