###########################################################################
###########################################################################
## Project      :Pace Transformation
## Work file    :prg1dataprogRepository_LoadJ9DandSPN4G_WF.properties
## $Revision    :1.0  $
## $Date        :May 10 2019 $
## $Author      :
## $UpDatedBy   :$
## $UpDated     :$
## Description  :This Workflow gets data from CRC4T for past 60 days and
##               staging and extracts last 30 days from transformed stg dataset
#########################################################################

###########################################################################
#Application Configuration (prg1)
###########################################################################
application=prg1
project=dataprogRepository
workflow=LoadJ9DandSPN4G
source=dataprogRepository-J9DandSPN-4G

###########################################################################
# Environment Based Configuration (Dev/QA/Prod)
###########################################################################
environment_hdfs_folder=/project/prg1/prg1DEV
current_user=prg1devp
current_date=2020-07-20

###########################################################################
# Path Configuration - NAS
###########################################################################
path_edge_node_root=/e/prg1_dev

###########################################################################
# Path Configuration - HDFS
###########################################################################
path_hdfs_prg1_lib=${environment_hdfs_folder}/Workflow/lib
path_hdfs_workflow_root=${environment_hdfs_folder}/Workflow/${project}/Workflows/${workflow}
path_hdfs_common_root=${environment_hdfs_folder}/Workflow/Common/Workflows/Common
output=${environment_hdfs_folder}/Warehouse/Staging/dataprogRepository/ncvdsum_pace_cmd_name_rspns_st_hte

# --------------Path Locations-----
path_hdfs_staging=${environment_hdfs_folder}/Warehouse/Staging/${project}
path_hdfs_secure=${environment_hdfs_folder}/Warehouse/Secure/PaceTransformation

path_hdfs_staging_table=${path_hdfs_staging}/ncvdsul_pace_tcu_strat_part_no_st_hte
path_hdfs_master_table=${path_hdfs_secure}/ncvdcul_pace_tcu_strat_part_no_sec_hte
path_hdfs_tcuecgsync_master_table=${path_hdfs_secure}/ncvdcul_pace_strat_part_no_sec_hte
path_hdfs_J9D_staging_table=${path_hdfs_staging}/ncvdsum_pace_cmd_name_rspns_st_hte

CRC4T_src_table=Ntblx01_fcproc_MSG_RAWDATA_k2_SEC_HTE
prs_src_table=Ntblx01_fcproc_MSG_PRS_RAWDATA_k2_SEC_HTE
psa_src_table=Ntblx01_fcproc_MSG_RAWDATA_k2_PSA_SEC_HTE
psu_src_table=Ntblx01_fcproc_MSG_RAWDATA_k2_PSU_SEC_HTE
spn_stg_table=NCVDSUL_PACE_TCU_STRAT_PART_NO_ST_HTE
spn_master_table=NCVDCUL_PACE_TCU_STRAT_PART_NO_SEC_HTE
cv2_stg_table=NCVDSUM_PACE_CMD_NAME_RSPNS_ST_HTE
cv2_master_table=NCVDCUM_PACE_CMD_NAME_RSPNS_SEC_HTE

#--------------reccalc Configuration--------------
path_hdfs_reccalc=${environment_hdfs_folder}/Warehouse/Public/reccalc
reccalc_driver_class=com.prdx.it.prg1.driver.reccalcDriver
reccalc_calculator_class=com.prdx.it.prg1.process.reccalc.ReceiveOnlyNoCountreccalcCalculator

###########################################################################
# Workflow  Configuration
###########################################################################

#------ Workflow Path --------------
workflow_path=${path_hdfs_workflow_root}/workflow.xml

#-----------Workflow Schedule Configuration--------------
frequency_interval=1440
start_date_time_in_utc=2019-05-01T00:00Z
end_date_time_in_utc=2019-10-01T00:00Z

#------ Workflow Email Configuration --------------------
email_recipient=XXXX@XXXX.COM
email_subject_failure=prg1 DEV: Workflow ${application}${project}_${workflow}_WF Failed

#------ Workflow Step Configuration ---------------------
CRC4T_strgypartno_query_days=7
CRC4T_J9D_query_days=30
hive_CRC4T_J9D_processdays=15


###########################################################################
# Cluster Configuration
###########################################################################
name_node=hdfs://NNDhdd3.NND.prdx.com:8020
job_tracker=NNDhdd3.NND.prdx.com:8050
log_viewer1=https://NNDhdd3e.NND.prdx.com:8000/oozie/list_oozie_workflow
log_viewer2=http://NNDhdd3.NND.prdx.com:11000/oozie/v1/job
log_viewer3=http://NNDhdd3.NND.prdx.com:11000/oozie?job=

###########################################################################
# Oozie  Configuration
###########################################################################
oozie_url=http://NNDhdd3.NND.prdx.com:11000/oozie
oozie.wf.application.path=${name_node}${path_hdfs_workflow_root}
oozie.libpath=${path_hdfs_workflow_root},${path_hdfs_prg1_lib}/lib,${path_hdfs_prg1_lib}/prg1Common.jar
oozie.use.system.libpath=true
oozie.launcher.mapreduce.task.classpath.user.precedence=true;
oozie.launcher.mapreduce.user.classpath.first=true;
oozie.launcher.mapreduce.job.user.classpath.first=true;

###########################################################################
# Database Configuration
###########################################################################

#--------------Hive Configuration----------
hive_database_name=prg1
hive_beeline_server=jdbc:hive2://NNDhdd3-zk-1.NND.prdx.com:2181,NNDhdd3-zk-2.NND.prdx.com:2181,NNDhdd3-zk-3.NND.prdx.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-apps
hive_kerberos_principal=hive/XXXX@XXXX.COM

#------------- Hbase Configuration -----------
path_hdfs_sharelib_hbase=/user/oozie/share/lib/hbase/
#path_hdfs_sharelib_joda=/user/oozie/share/lib/hbase/joda-time-2.8.1.jar

###########################################################################
# Kerberos Configuration
###########################################################################
kerberos_user_name=${user.name}
kerberos_principal=${user.name}@NND.prdx.COM
kerberos_keytab_filename=${user.name}.keytab
kerberos_keytab_file=${environment_hdfs_folder}/Workflow/KEYS/${kerberos_keytab_filename}

###########################################################################
#Spark Configuration
###########################################################################
spark_master=yarn
spark_deploy_mode=cluster
spark_max_executors=200
spark_driver_memory=16g
spark_executor_memory=24g
spark_executor_cores=4
queue=prg1
#output=${environment_hdfs_folder}/Warehouse/Staging/dataprogRepository/nscvsgd_actv_vin_summ_prs_st_hte
spark_network_timeout=800
spark_ui_port=5052
spark_jars=/usr/hdp/current/spark-client/lib/datanucleus-api-jdo-3.2.6.jar,/usr/hdp/current/spark-client/lib/datanucleus-rdbms-3.2.9.jar,/usr/hdp/current/spark-client/lib/datanucleus-core-3.2.10.jar
spark_driver_memory=16g
spark_num_executors=90
spark_sql_shuffle_partitions=1000
spark_sql_orc_filterPushdown=true
#spark_yarn_executor_memoryOverhead=4096k
spark_executor_memoryOverhead=4096k
spark_core_connection_ack_wait_timeout=600
spark_task_maxfailures=20
spark_shuffle_io_maxRetries=20
spark_dynamicalLocation_enabled=false
spark_sql_orc_enabled=true
spark_sql_hive_convertMetaStoreOrc=true
spark_sql_orc_char_enabled=true
spark_files=/usr/hdp/current/spark2-client/conf/hive-site.xml